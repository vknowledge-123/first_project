{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56fbbb0",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing Tools :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148da90e",
   "metadata": {},
   "source": [
    "### Importing The Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da452a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da5af51",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5369cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"Data.csv\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fc8e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Data.csv\")\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579a5f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0938ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa24dcd",
   "metadata": {},
   "source": [
    "# Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "684d7279",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Imports SimpleImputer from the sklearn.impute module.\n",
    "It is used to handle missing data (e.g., NaN values).\n",
    "\n",
    "-- Creates an object called imputer.\n",
    "missing_values=np.nan: Treats all np.nan entries as missing.\n",
    "strategy=\"mean\": Missing values will be filled with the mean of each column.\n",
    "\n",
    "-- fit() -- \"Learn the Pattern\"\n",
    "Look at the training data and learn the average (mean) \n",
    "In the case of missing values,fit() will calculate the mean \n",
    "for each column with missing data.\n",
    "It does not change the data — it just prepares.\n",
    "\n",
    "-- transform() — \"Apply the fix\"\n",
    "Using the information from fit(), transform() will replace \n",
    "the missing values with the calculated mean.\n",
    "This step modifies the data by filling in the missing values.\n",
    "'''\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values = np.nan, strategy = \"mean\")\n",
    "imputer.fit(X[:, 1:3])\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f0542c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377bac8",
   "metadata": {},
   "source": [
    "# Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98324f39",
   "metadata": {},
   "source": [
    "### Encoding the Indpendent Variable :-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "700e7393",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "→ sklearn.compose \n",
    "ColumnTransformer: to apply different preprocessing to different columns.\n",
    "\n",
    "→ sklearn.preprocessing : This is scikit-learn’s toolbox for cleaning and preparing data.\n",
    " OneHotEncoder(): Converts categories into separate columns of 0s and 1s.\n",
    "What happened?\n",
    "Country\tFrance\tGermany\tSpain\n",
    "France\t1\t0\t0\n",
    "Germany\t0\t1\t0\n",
    "Spain\t0\t0\t1\n",
    "France\t1\t0\t0\n",
    "Each category becomes a new column.\n",
    "The row has 1 where the category matches, and 0 elsewhere.\n",
    "This helps machine learning models understand text data as numbers\n",
    "\n",
    "--transformers=[...]: this is a list of what transformations to apply.\n",
    "'encoder': just a name for the transformation (can be anything).\n",
    "[0]: apply this only to column 0 (the first column), \n",
    "which is usually where the categorical data is.\n",
    "\n",
    "remainder='passthrough': this means \"leave the other columns as they are\" \n",
    "— only apply OneHotEncoding to column 0, and keep the rest.\n",
    "'''\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])], remainder = 'passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286c8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6271c48e",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dac3d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-- fit(y):\n",
    "Looks at the unique values in y (e.g., \"Yes\" and \"No\").\n",
    "It learns what values exist.\n",
    "-- transform(y):\n",
    "Replaces the text with numbers:\n",
    "\"Yes\" → 1\n",
    "\"No\" → 0\n",
    "So \"Yes\", \"No\", \"Yes\" becomes 1, 0, 1\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80ca61fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964ae66",
   "metadata": {},
   "source": [
    "### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b09602a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "-- from sklearn.model_selection import train_test_split\n",
    "from → You're taking something from a package.\n",
    "sklearn.model_selection → This is the part of scikit-learn that helps split your data.\n",
    "import train_test_split → You're bringing in the function called train_test_split to use it.\n",
    "In short: \"Bring in the tool to split the data.\n",
    "\n",
    "-- X_train, X_test, y_train, y_test \n",
    "Put the training part of X into X_train\n",
    "Put the test part of X into X_test\n",
    "Put the training part of y into y_train\n",
    "Put the test part of y into y_test\n",
    "\n",
    "-- train_test_split(X, y, ...)\n",
    "This function takes:\n",
    "X = all input features (like age, country, salary)\n",
    "y = all output labels (like \"yes\" or \"no\")\n",
    " \"Split both X and y.\"\n",
    "\n",
    "-- test_size=0.2\n",
    "This means 20% of the data will be used for testing, \n",
    "and 80% for training.\n",
    "\n",
    "-- random_state=1\n",
    "Make the split the same each time, so you get consistent results.\"\n",
    "'''\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dadbebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10fb1e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db53496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47c52f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f31d9",
   "metadata": {},
   "source": [
    "### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6bc03fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from → Take something from a library/module.\n",
    "\n",
    "sklearn.preprocessing → This is scikit-learn’s toolbox for cleaning and preparing data.\n",
    "\n",
    "import StandardScaler → StandardScaler: \n",
    "A tool inside preprocessing to scale/normalize numbers.\n",
    "It scales numbers so they have: \n",
    "Mean = 0\n",
    "Standard deviation = 1\n",
    "This helps models learn faster and better.\n",
    "\n",
    "sc = StandardScaler()\n",
    "You're creating an object called sc.\n",
    "Now sc can be used to apply scaling.\n",
    "Create a scaler that will change your numbers to a standard format.\n",
    "\n",
    "X_train[:, 3:]\n",
    "X_train → Your training data.\n",
    "[:, 3:] → Select all rows (:), and columns starting from index 3 to the end.\n",
    "This assumes columns 0, 1, 2 are already processed (e.g., OneHotEncoded),\n",
    "columns from 3 onward are numeric features like salary or age.\n",
    "\n",
    " sc.fit_transform(X_train[:, 3:])\n",
    "fit → Look at the training data and learn the average (mean) and spread (standard deviation).\n",
    "transform → Use what it learned to scale the numbers.\n",
    "\n",
    "X_train[:, 3:] = ...\n",
    "This replaces the old values with the new, scaled values.\n",
    "\n",
    "X_test[:, 3:] = ...\n",
    "This replaces the original values in those columns with the scaled values, so the test data is ready for prediction.\n",
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "053e7ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bbd8d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
      " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd5f6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
